{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import snap\n",
    "import csv\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from sklearn import metrics\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extractSnapGraph(filename):\n",
    "    NetworkXGraph = nx.readwrite.gexf.read_gexf(filename)\n",
    "    newFileName = filename.split('.')\n",
    "    finalFileName = newFileName[0] + '.edges'\n",
    "    print finalFileName\n",
    "    nx.write_edgelist(NetworkXGraph, finalFileName)\n",
    "    SNAPGraph = snap.LoadEdgeList(snap.PUNGraph, finalFileName, 0, 1)\n",
    "    return SNAPGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extractNetworkXGraph(filename):\n",
    "    NetworkXGraph = nx.readwrite.gexf.read_gexf(filename)\n",
    "    return NetworkXGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_dictionary(file_name):\n",
    "    with open(file_name + '.pkl', 'rb') as current_file:\n",
    "        return pickle.load(current_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dictGenresToIds = load_dictionary('genre_to_ids')\n",
    "dictIdToGenres = load_dictionary('id_to_genres')\n",
    "dictIdToMovieName = load_dictionary('id_to_movie_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "genres = []\n",
    "for key, value in dictGenresToIds.iteritems():\n",
    "    genres.append(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "genres_to_ids = {}\n",
    "for i in range(len(genres)):\n",
    "    genres_to_ids[genres[i]] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_dictIdToGenres = {}\n",
    "for movie_id, genres_list in dictIdToGenres.iteritems():\n",
    "    if movie_id not in new_dictIdToGenres.iterkeys():\n",
    "        new_dictIdToGenres[movie_id] = []\n",
    "    for i in range(len(genres_list)):\n",
    "        genre = genres_list[i]\n",
    "        new_dictIdToGenres[movie_id].append(genres_to_ids[genre])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_dictIdToBinaryGenres = {} # id maps to a bit vector\n",
    "for movie_id, genres_ids_list in new_dictIdToGenres.iteritems():\n",
    "    bit_vector = []\n",
    "    for i in range(len(genres)):\n",
    "        if i in genres_ids_list:\n",
    "            bit_vector.append(1)\n",
    "        else:\n",
    "            bit_vector.append(0)\n",
    "    new_dictIdToBinaryGenres[movie_id] = bit_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_dictGenresToIds = {}\n",
    "for genre, ids_list in dictGenresToIds.iteritems():\n",
    "    genre_id = genres_to_ids[genre]\n",
    "    new_dictGenresToIds[genre_id] = ids_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_df = pd.read_csv('featureMatrix.csv', sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_data = []\n",
    "Y_data = []\n",
    "for index, row in new_df.iterrows():\n",
    "    movie_id = row[0]\n",
    "    if movie_id in new_dictIdToBinaryGenres.iterkeys():\n",
    "        genres_list = new_dictIdToBinaryGenres[movie_id]\n",
    "        Y_data.append(genres_list)\n",
    "    else:\n",
    "        continue\n",
    "    new_movie = []\n",
    "    for i in range(1, len(row)):\n",
    "        new_movie.append(row[i])\n",
    "    X_data.append(new_movie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_data = np.asarray(X_data)\n",
    "Y_data = np.asarray(Y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = X_data[0:700]\n",
    "Y_train = Y_data[0:700]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = X_data[700:-1]\n",
    "Y_test = Y_data[700:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(activation='tanh', solver='adam', alpha=1e-2, batch_size = 10,\n",
    "                    learning_rate = 'invscaling', tol = 0.000001,\n",
    "                    hidden_layer_sizes=(100, 2), max_iter = 1000, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='tanh', alpha=0.01, batch_size=10, beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100, 2), learning_rate='invscaling',\n",
       "       learning_rate_init=0.001, max_iter=1000, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
       "       solver='adam', tol=1e-06, validation_fraction=0.1, verbose=False,\n",
       "       warm_start=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score = mlp.score(X_test, Y_test) # num that matches exactly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Y_mlp_result = mlp.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "true_positive = 0\n",
    "true_negative = 0\n",
    "false_positive = 0\n",
    "false_negative = 0\n",
    "count = 0\n",
    "for i in range(len(Y_mlp_result)):\n",
    "    for j in range(len(Y_mlp_result[i])):\n",
    "        count += 1\n",
    "        if Y_test[i][j] == 1 and Y_mlp_result[i][j] == 1:\n",
    "            true_positive += 1\n",
    "        if Y_test[i][j] == 0 and Y_mlp_result[i][j] == 0:\n",
    "            true_negative += 1\n",
    "        if Y_test[i][j] == 1 and Y_mlp_result[i][j] == 0:\n",
    "            false_negative += 1\n",
    "        if Y_test[i][j] == 0 and Y_mlp_result[i][j] == 1:\n",
    "            false_positive += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "right = true_negative + true_positive\n",
    "total = true_positive + true_negative + false_positive + false_negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.752777777778\n"
     ]
    }
   ],
   "source": [
    "print float(right)/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fpr = float(false_positive) / (false_positive + true_negative)\n",
    "tpr = float(true_positive) / (true_positive + false_negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = np.array([1, 1, 2, 2])\n",
    "pred = np.array([0.1, 0.4, 0.35, 0.8])\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y, pred, pos_label=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.506656346749\n"
     ]
    }
   ],
   "source": [
    "print roc_auc_score(Y_test, Y_mlp_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_df = pd.read_csv('featureMatrix.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "movies = []\n",
    "for movie_name in dictIdToMovieName.itervalues():\n",
    "    movies.append(movie_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "movie_df = pd.read_csv('tmdb_5000_movies.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/qldo18/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:3: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for i in range(len(movie_df)):\n",
    "    if movie_df.loc[i]['title'] in movies:\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "523"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "budget, popularity, runtime, revenue, vote_average, vote_count # production_company"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
